# Prompt_Engineering_for_Vision_Models
Prompt engineering is used not only in text models but also in vision models. Depending on the vision model, they may use text prompts, but can also work with pixel coordinates, bounding boxes, or segmentation masks.

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTkq4KRHz_FBMATU1b69VhM2HgqoaaLkCLCqw&usqp=CAU)

Prompt engineering for diffusion models is the process of creating text inputs, or prompts, to guide generative AI models to produce the desired outputs. In the context of diffusion models, prompts are text descriptions of a subject that the user wants to create using an AI image generator. Diffusion models take two primary inputs, a seed integer and a text prompt, and translate them into a fixed point in the model's latent space. The seed integer is usually automatically generated, but the user provides the text prompt

**Here are some tips for prompt engineering for Stable Diffusion:**
- Determine the type of artwork
- Describe the subject
- Detail the scene
- Specify the style
- Include lighting and detail
- State the composition
- Define the color scheme
- Avoid over-complexity 


